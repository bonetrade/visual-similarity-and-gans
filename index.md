## Visual Similarity and Generative Adversarial Networks

This is an experiment; the idea is that we can train the machine to 'know' what certain classes of archaeological materials look like, sufficient that the machine (the GAN) can spoof the detector (the CNN) to accept that the generated image is a real image. This has the effect of creating a kind of caricature of the the elements in a photograph that 'matter' to the machine. Then, using something like PixPlot, the machine will group these generated images in terms of their visual similarities. In this way, we end up with a kind of computational stylistics. 

[Red Figure Pottery; trained on images from the MET](generated_red_fig)

[Skulls for sale; trained on images found via that hashtag on Instagram](generated_skulls). NB none of the depictions of human remains are actual humans - this is the machine's understanding.
